{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data File and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = \"SHOPEE_MAYBELLINE_CLEAN_V2.csv\"\n",
    "data_file = \"Lazada_sentiment.csv\"\n",
    "data = pd.read_csv(data_file)\n",
    "data.columns = data.columns.str.strip().str.replace(\" \",\"_\")\n",
    "# data.info()\n",
    "# data.head()\n",
    "\n",
    "# data.drop(columns=['Brand','Category','Product_Name','Price','Reviewer','Product_Purchase','Ratings','Date_Of_Review','Response', 'Topic'])\n",
    "# review_list = data['Review'].tolist()\n",
    "# polarity_list = data['Polarity'].tolist()\n",
    "\n",
    "reviews = data['Review']\n",
    "# polarity = data['Polarity']\n",
    "# print (reviews)\n",
    "\n",
    "review_docs = []\n",
    "for each_reviews in reviews:\n",
    "    temp = each_reviews.split(\" \")\n",
    "    review_docs.append(temp)\n",
    "# print (review_docs)\n",
    "\n",
    "# Make sure all words are in lowercase\n",
    "reviews_lower = [[each_word.lower() for each_word in each_review] for each_review in review_docs]\n",
    "# print (reviews_lower)\n",
    "\n",
    "# Use regular expressions to keep only allphabetical words\n",
    "reviews_alpha = [[each_word for each_word in each_review if re.search('^[a-z]+$', each_word)] for each_review in reviews_lower]\n",
    "# print (reviews_alpha)\n",
    "\n",
    "# Remove stop words\n",
    "stop_list = stopwords.words('english')\n",
    "reviews_stop = [[each_word for each_word in each_review if each_word not in stop_list] for each_review in reviews_alpha]\n",
    "# print (reviews_stop)\n",
    "\n",
    "# Porter Stemming\n",
    "stemmer = PorterStemmer()\n",
    "reviews_stem = [[stemmer.stem(each_word) for each_word in each_review] for each_review in reviews_stop]\n",
    "# print (reviews_stem)\n",
    "\n",
    "all_data_cleaned = []\n",
    "for each_sentence in reviews_stem:\n",
    "    sentence = \"\"\n",
    "    for each_word in each_sentence:\n",
    "        sentence += each_word + \" \"\n",
    "    sentence = sentence[0:-1]\n",
    "    all_data_cleaned.append(sentence)\n",
    "# print (all_data_cleaned)\n",
    "\n",
    "polarity_raw = data['Polarity']\n",
    "polarity_0_and_1 = []\n",
    "for each_polarity in polarity_raw:\n",
    "    if int(each_polarity) == int(\"0\"):\n",
    "        polarity_0_and_1.append(0.5)\n",
    "    if int(each_polarity) == int(\"-1\"):\n",
    "        polarity_0_and_1.append(int(0))\n",
    "    if int(each_polarity) == int(\"1\"):\n",
    "        polarity_0_and_1.append(int(1))\n",
    "# print (polarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - Count Vector\n",
    "1. Multinomial NB\n",
    "2. Bernoulli NB\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Multinomial Naive Bayes with Count Vector is: 74.38949627852426\n",
      "Accuracy of Multinomial Naive Bayes with Count Vector is: 74.88524590163934\n",
      "F1-score of Bernoulli Naive Bayes with Count Vector is: 78.1315113690941\n",
      "Accuracy of Bernoulli Naive Bayes with Count Vector is: 78.68852459016394\n",
      "F1-score of Logistic Regression with Count Vector is: 84.4704797397741\n",
      "Accuracy of Logistic Regression with Count Vector is: 84.78688524590164\n",
      "F1-score of Support Vector Machine with Count Vector is: 87.01908836686619\n",
      "Accuracy of Support Vector Machine with Count Vector is: 87.27868852459017\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "### done\n",
    "\n",
    "Classifiers = [MultinomialNB(), BernoulliNB(), LogisticRegression(), SVC()]\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "countVectorizer = CountVectorizer(min_df = 4, max_df=0.85)\n",
    "X_train = countVectorizer.fit_transform(X_train)\n",
    "X_test = countVectorizer.transform(X_test)\n",
    "\n",
    "for i in range(len(Classifiers)):\n",
    "    clf = Classifiers[i]\n",
    "    clf_name = \"Test\"\n",
    "    \n",
    "    if i == int(0):\n",
    "        clf_name = \"Multinomial Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(1):\n",
    "        clf_name = \"Bernoulli Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(2):\n",
    "        clf_name = \"Logistic Regression\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(3):\n",
    "        clf_name = \"Support Vector Machine\"\n",
    "        clf = Classifiers[i]\n",
    "#         parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "        parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "        clf = GridSearchCV(estimator = clf, param_grid = parameters)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_ypred = clf.predict(X_test)\n",
    "    f1_clf = f1_score(y_test, clf_ypred, average = 'weighted')\n",
    "    accuracy_clf = accuracy_score(y_test, clf_ypred)\n",
    "    print (\"F1-score of\", clf_name, \"with Count Vector is:\", f1_clf*100)\n",
    "    print (\"Accuracy of\", clf_name, \"with Count Vector is:\", accuracy_clf*100)\n",
    "    \n",
    "    if clf_name == \"Support Vector Machine\":\n",
    "        print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - TFIDF (use_idf = False)\n",
    "1. Multinomial NB\n",
    "2. Bernoulli NB\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Multinomial Naive Bayes with TFIDF (use_idf = False) is: 70.62505296771751\n",
      "Accuracy of Multinomial Naive Bayes with TFIDF (use_idf = False) is: 72.85245901639344\n",
      "F1-score of Bernoulli Naive Bayes with TFIDF (use_idf = False) is: 78.1315113690941\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF (use_idf = False) is: 78.68852459016394\n",
      "F1-score of Logistic Regression with TFIDF (use_idf = False) is: 79.84358844245423\n",
      "Accuracy of Logistic Regression with TFIDF (use_idf = False) is: 81.04918032786885\n",
      "F1-score of Support Vector Machine with TFIDF (use_idf = False) is: 86.38192827841739\n",
      "Accuracy of Support Vector Machine with TFIDF (use_idf = False) is: 86.49180327868852\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "### done\n",
    "\n",
    "Classifiers = [MultinomialNB(), BernoulliNB(), LogisticRegression(), SVC()]\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tf_Vectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tf_Vectorizer.fit_transform(X_train)\n",
    "X_test = tf_Vectorizer.transform(X_test)\n",
    "\n",
    "for i in range(len(Classifiers)):\n",
    "    clf = Classifiers[i]\n",
    "    clf_name = \"Test\"\n",
    "    \n",
    "    if i == int(0):\n",
    "        clf_name = \"Multinomial Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(1):\n",
    "        clf_name = \"Bernoulli Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(2):\n",
    "        clf_name = \"Logistic Regression\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(3):\n",
    "        clf_name = \"Support Vector Machine\"\n",
    "        clf = Classifiers[i]\n",
    "#         parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "        parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "        clf = GridSearchCV(estimator = clf, param_grid = parameters)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_ypred = clf.predict(X_test)\n",
    "    f1_clf = f1_score(y_test, clf_ypred, average = 'weighted')\n",
    "    accuracy_clf = accuracy_score(y_test, clf_ypred)\n",
    "    print (\"F1-score of\", clf_name, \"with TFIDF (use_idf = False) is:\", f1_clf*100)\n",
    "    print (\"Accuracy of\", clf_name, \"with TFIDF (use_idf = False) is:\", accuracy_clf*100)\n",
    "    \n",
    "    if clf_name == \"Support Vector Machine\":\n",
    "        print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - TFIDF (use_idf = True)\n",
    "1. Multinomial NB\n",
    "2. Bernoulli NB\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Multinomial Naive Bayes with TFIDF (use_idf = True) is: 73.45205689395802\n",
      "Accuracy of Multinomial Naive Bayes with TFIDF (use_idf = True) is: 74.88524590163934\n",
      "F1-score of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 78.1315113690941\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 78.68852459016394\n",
      "F1-score of Logistic Regression with TFIDF (use_idf = True) is: 81.81270330259666\n",
      "Accuracy of Logistic Regression with TFIDF (use_idf = True) is: 82.68852459016394\n",
      "F1-score of Support Vector Machine with TFIDF (use_idf = True) is: 86.52612669729935\n",
      "Accuracy of Support Vector Machine with TFIDF (use_idf = True) is: 86.62295081967213\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "### done\n",
    "\n",
    "Classifiers = [MultinomialNB(), BernoulliNB(), LogisticRegression(), SVC()]\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "for i in range(len(Classifiers)):\n",
    "    clf = Classifiers[i]\n",
    "    clf_name = \"Test\"\n",
    "    \n",
    "    if i == int(0):\n",
    "        clf_name = \"Multinomial Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(1):\n",
    "        clf_name = \"Bernoulli Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(2):\n",
    "        clf_name = \"Logistic Regression\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i == int(3):\n",
    "        clf_name = \"Support Vector Machine\"\n",
    "        clf = Classifiers[i]\n",
    "#         parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "        parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "        clf = GridSearchCV(estimator = clf, param_grid = parameters)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_ypred = clf.predict(X_test)\n",
    "    f1_clf = f1_score(y_test, clf_ypred, average = 'weighted')\n",
    "    accuracy_clf = accuracy_score(y_test, clf_ypred)\n",
    "    print (\"F1-score of\", clf_name, \"with TFIDF (use_idf = True) is:\", f1_clf*100)\n",
    "    print (\"Accuracy of\", clf_name, \"with TFIDF (use_idf = True) is:\", accuracy_clf*100)\n",
    "    \n",
    "    if clf_name == \"Support Vector Machine\":\n",
    "        print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - PCA (n=2)\n",
    "Multinomial Naive Bayes cannot do PCA as the input is negative\n",
    "2. Bernoulli NB\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 32.86082463112957\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 49.57377049180327\n",
      "F1-score of Logistic Regression with TFIDF (use_idf = True) is: 40.10413131989504\n",
      "Accuracy of Logistic Regression with TFIDF (use_idf = True) is: 45.50819672131148\n",
      "F1-score of Support Vector Machine with TFIDF (use_idf = True) is: 32.86082463112957\n",
      "Accuracy of Support Vector Machine with TFIDF (use_idf = True) is: 49.57377049180327\n",
      "{'C': 1, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "Classifiers = [BernoulliNB(), LogisticRegression(), SVC()]\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df = 0.85)\n",
    "vectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "X_train = pca.fit_transform(X_train.toarray())\n",
    "\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_train = pd.concat([df_train, y_train], axis = 1, ignore_index = True)\n",
    "df_train.columns = ['pca_1', 'pca_2', 'target']\n",
    "df_train['pca_1'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_2'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['target'].replace(\"\", np.nan, inplace = True)\n",
    "df_train.dropna(subset=['pca_1', 'pca_2', 'target'], inplace = True)\n",
    "df_train['pca_1'] = df_train['pca_1'].astype(float)\n",
    "df_train['pca_2'] = df_train['pca_2'].astype(float)\n",
    "\n",
    "X_test = pca.transform(X_test.toarray())\n",
    "df_test = pd.DataFrame(X_test)\n",
    "df_test = pd.concat([df_test, y_test], axis = 1, ignore_index = True)\n",
    "df_test.columns = ['pca_1', 'pca_2', 'target']\n",
    "df_test.describe(include='all')\n",
    "df_test['pca_1'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_2'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['target'].replace(\"\", np.nan, inplace = True)\n",
    "df_test.dropna(subset=['pca_1', 'pca_2', 'target'], inplace = True)\n",
    "df_test['pca_1'] = df_test['pca_1'].astype(float)\n",
    "df_test['pca_2'] = df_test['pca_2'].astype(float)\n",
    "\n",
    "for i in range(len(Classifiers)):\n",
    "    clf = Classifiers[i]\n",
    "    clf_name = \"Test\"\n",
    "    \n",
    "    if i+1 == int(0):\n",
    "        clf_name = \"Multinomial Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(1):\n",
    "        clf_name = \"Bernoulli Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(2):\n",
    "        clf_name = \"Logistic Regression\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(3):\n",
    "        clf_name = \"Support Vector Machine\"\n",
    "        clf = Classifiers[i]\n",
    "#         parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "        parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "        clf = GridSearchCV(estimator = clf, param_grid = parameters)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_ypred = clf.predict(X_test)\n",
    "    f1_clf = f1_score(y_test, clf_ypred, average = 'weighted')\n",
    "    accuracy_clf = accuracy_score(y_test, clf_ypred)\n",
    "    print (\"F1-score of\", clf_name, \"with TFIDF (use_idf = True) is:\", f1_clf*100)\n",
    "    print (\"Accuracy of\", clf_name, \"with TFIDF (use_idf = True) is:\", accuracy_clf*100)\n",
    "    \n",
    "    if clf_name == \"Support Vector Machine\":\n",
    "        print (clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - PCA (n=3)\n",
    "Multinomial Naive Bayes cannot do PCA as the input is negative\n",
    "2. Bernoulli NB\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 51.96431731346798\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 54.81967213114755\n",
      "F1-score of Logistic Regression with TFIDF (use_idf = True) is: 43.7819197964395\n",
      "Accuracy of Logistic Regression with TFIDF (use_idf = True) is: 47.21311475409836\n",
      "F1-score of Support Vector Machine with TFIDF (use_idf = True) is: 49.4904666008311\n",
      "Accuracy of Support Vector Machine with TFIDF (use_idf = True) is: 52.91803278688525\n",
      "{'C': 2, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "Classifiers = [BernoulliNB(), LogisticRegression(), SVC()]\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df = 0.85)\n",
    "vectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 3)\n",
    "X_train = pca.fit_transform(X_train.toarray())\n",
    "\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_train = pd.concat([df_train, y_train], axis = 1, ignore_index = True)\n",
    "df_train.columns = ['pca_1', 'pca_2', 'pca_3', 'target']\n",
    "df_train['pca_1'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_2'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_3'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['target'].replace(\"\", np.nan, inplace = True)\n",
    "df_train.dropna(subset=['pca_1', 'pca_2', 'pca_3', 'target'], inplace = True)\n",
    "df_train['pca_1'] = df_train['pca_1'].astype(float)\n",
    "df_train['pca_2'] = df_train['pca_2'].astype(float)\n",
    "df_train['pca_3'] = df_train['pca_3'].astype(float)\n",
    "\n",
    "X_test = pca.transform(X_test.toarray())\n",
    "df_test = pd.DataFrame(X_test)\n",
    "df_test = pd.concat([df_test, y_test], axis = 1, ignore_index = True)\n",
    "df_test.columns = ['pca_1', 'pca_2', 'pca_3', 'target']\n",
    "df_test.describe(include='all')\n",
    "df_test['pca_1'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_2'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_3'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['target'].replace(\"\", np.nan, inplace = True)\n",
    "df_test.dropna(subset=['pca_1', 'pca_2', 'pca_3', 'target'], inplace = True)\n",
    "df_test['pca_1'] = df_test['pca_1'].astype(float)\n",
    "df_test['pca_2'] = df_test['pca_2'].astype(float)\n",
    "df_test['pca_3'] = df_test['pca_3'].astype(float)\n",
    "\n",
    "for i in range(len(Classifiers)):\n",
    "    clf = Classifiers[i]\n",
    "    clf_name = \"Test\"\n",
    "    \n",
    "    if i+1 == int(0):\n",
    "        clf_name = \"Multinomial Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(1):\n",
    "        clf_name = \"Bernoulli Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(2):\n",
    "        clf_name = \"Logistic Regression\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(3):\n",
    "        clf_name = \"Support Vector Machine\"\n",
    "        clf = Classifiers[i]\n",
    "#         parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "        parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "        clf = GridSearchCV(estimator = clf, param_grid = parameters)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_ypred = clf.predict(X_test)\n",
    "    f1_clf = f1_score(y_test, clf_ypred, average = 'weighted')\n",
    "    accuracy_clf = accuracy_score(y_test, clf_ypred)\n",
    "    print (\"F1-score of\", clf_name, \"with TFIDF (use_idf = True) is:\", f1_clf*100)\n",
    "    print (\"Accuracy of\", clf_name, \"with TFIDF (use_idf = True) is:\", accuracy_clf*100)\n",
    "    \n",
    "    if clf_name == \"Support Vector Machine\":\n",
    "        print (clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - PCA (n=4)\n",
    "Multinomial Naive Bayes cannot do PCA as the input is negative\n",
    "2. Bernoulli NB\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 51.96431731346798\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 54.81967213114755\n",
      "F1-score of Logistic Regression with TFIDF (use_idf = True) is: 42.861789750759925\n",
      "Accuracy of Logistic Regression with TFIDF (use_idf = True) is: 47.21311475409836\n",
      "F1-score of Support Vector Machine with TFIDF (use_idf = True) is: 39.289634468424254\n",
      "Accuracy of Support Vector Machine with TFIDF (use_idf = True) is: 48.98360655737705\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "Classifiers = [BernoulliNB(), LogisticRegression(), SVC()]\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df = 0.85)\n",
    "vectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 4)\n",
    "X_train = pca.fit_transform(X_train.toarray())\n",
    "\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_train = pd.concat([df_train, y_train], axis = 1, ignore_index = True)\n",
    "df_train.columns = ['pca_1', 'pca_2', 'pca_3', 'pca_4', 'target']\n",
    "df_train['pca_1'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_2'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_3'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_4'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['target'].replace(\"\", np.nan, inplace = True)\n",
    "df_train.dropna(subset=['pca_1', 'pca_2', 'pca_3', 'pca_4', 'target'], inplace = True)\n",
    "df_train['pca_1'] = df_train['pca_1'].astype(float)\n",
    "df_train['pca_2'] = df_train['pca_2'].astype(float)\n",
    "df_train['pca_3'] = df_train['pca_3'].astype(float)\n",
    "df_train['pca_4'] = df_train['pca_4'].astype(float)\n",
    "\n",
    "X_test = pca.transform(X_test.toarray())\n",
    "df_test = pd.DataFrame(X_test)\n",
    "df_test = pd.concat([df_test, y_test], axis = 1, ignore_index = True)\n",
    "df_test.columns = ['pca_1', 'pca_2', 'pca_3', 'pca_4', 'target']\n",
    "df_test.describe(include='all')\n",
    "df_test['pca_1'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_2'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_3'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_4'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['target'].replace(\"\", np.nan, inplace = True)\n",
    "df_test.dropna(subset=['pca_1', 'pca_2', 'pca_3', 'pca_4', 'target'], inplace = True)\n",
    "df_test['pca_1'] = df_test['pca_1'].astype(float)\n",
    "df_test['pca_2'] = df_test['pca_2'].astype(float)\n",
    "df_test['pca_3'] = df_test['pca_3'].astype(float)\n",
    "df_test['pca_4'] = df_test['pca_4'].astype(float)\n",
    "\n",
    "for i in range(len(Classifiers)):\n",
    "    clf = Classifiers[i]\n",
    "    clf_name = \"Test\"\n",
    "    \n",
    "    if i+1 == int(0):\n",
    "        clf_name = \"Multinomial Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(1):\n",
    "        clf_name = \"Bernoulli Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(2):\n",
    "        clf_name = \"Logistic Regression\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(3):\n",
    "        clf_name = \"Support Vector Machine\"\n",
    "        clf = Classifiers[i]\n",
    "#         parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "        parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "        clf = GridSearchCV(estimator = clf, param_grid = parameters)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_ypred = clf.predict(X_test)\n",
    "    f1_clf = f1_score(y_test, clf_ypred, average = 'weighted')\n",
    "    accuracy_clf = accuracy_score(y_test, clf_ypred)\n",
    "    print (\"F1-score of\", clf_name, \"with TFIDF (use_idf = True) is:\", f1_clf*100)\n",
    "    print (\"Accuracy of\", clf_name, \"with TFIDF (use_idf = True) is:\", accuracy_clf*100)\n",
    "    \n",
    "    if clf_name == \"Support Vector Machine\":\n",
    "        print (clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - PCA (n=5)\n",
    "Multinomial Naive Bayes cannot do PCA as the input is negative\n",
    "2. Bernoulli NB\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 51.87880776394781\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF (use_idf = True) is: 55.47540983606557\n",
      "F1-score of Logistic Regression with TFIDF (use_idf = True) is: 43.094841922096194\n",
      "Accuracy of Logistic Regression with TFIDF (use_idf = True) is: 47.278688524590166\n",
      "F1-score of Support Vector Machine with TFIDF (use_idf = True) is: 39.41974191235565\n",
      "Accuracy of Support Vector Machine with TFIDF (use_idf = True) is: 48.98360655737705\n",
      "{'C': 2, 'degree': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "Classifiers = [BernoulliNB(), LogisticRegression(), SVC()]\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df = 0.85)\n",
    "vectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 5)\n",
    "X_train = pca.fit_transform(X_train.toarray())\n",
    "\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_train = pd.concat([df_train, y_train], axis = 1, ignore_index = True)\n",
    "df_train.columns = ['pca_1', 'pca_2', 'pca_3', 'pca_4', 'pca_5', 'target']\n",
    "df_train['pca_1'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_2'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_3'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_4'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['pca_5'].replace(\"\", np.nan, inplace = True)\n",
    "df_train['target'].replace(\"\", np.nan, inplace = True)\n",
    "df_train.dropna(subset=['pca_1', 'pca_2', 'pca_3', 'pca_4', 'pca_5', 'target'], inplace = True)\n",
    "df_train['pca_1'] = df_train['pca_1'].astype(float)\n",
    "df_train['pca_2'] = df_train['pca_2'].astype(float)\n",
    "df_train['pca_3'] = df_train['pca_3'].astype(float)\n",
    "df_train['pca_4'] = df_train['pca_4'].astype(float)\n",
    "df_train['pca_5'] = df_train['pca_5'].astype(float)\n",
    "\n",
    "X_test = pca.transform(X_test.toarray())\n",
    "df_test = pd.DataFrame(X_test)\n",
    "df_test = pd.concat([df_test, y_test], axis = 1, ignore_index = True)\n",
    "df_test.columns = ['pca_1', 'pca_2', 'pca_3', 'pca_4', 'pca_5', 'target']\n",
    "df_test.describe(include='all')\n",
    "df_test['pca_1'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_2'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_3'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_4'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['pca_5'].replace(\"\", np.nan, inplace = True)\n",
    "df_test['target'].replace(\"\", np.nan, inplace = True)\n",
    "df_test.dropna(subset=['pca_1', 'pca_2', 'pca_3', 'pca_4', 'pca_5', 'target'], inplace = True)\n",
    "df_test['pca_1'] = df_test['pca_1'].astype(float)\n",
    "df_test['pca_2'] = df_test['pca_2'].astype(float)\n",
    "df_test['pca_3'] = df_test['pca_3'].astype(float)\n",
    "df_test['pca_4'] = df_test['pca_4'].astype(float)\n",
    "df_test['pca_5'] = df_test['pca_5'].astype(float)\n",
    "\n",
    "for i in range(len(Classifiers)):\n",
    "    clf = Classifiers[i]\n",
    "    clf_name = \"Test\"\n",
    "    \n",
    "    if i+1 == int(0):\n",
    "        clf_name = \"Multinomial Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(1):\n",
    "        clf_name = \"Bernoulli Naive Bayes\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(2):\n",
    "        clf_name = \"Logistic Regression\"\n",
    "        clf = Classifiers[i]\n",
    "    elif i+1 == int(3):\n",
    "        clf_name = \"Support Vector Machine\"\n",
    "        clf = Classifiers[i]\n",
    "#         parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "        parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "        clf = GridSearchCV(estimator = clf, param_grid = parameters)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_ypred = clf.predict(X_test)\n",
    "    f1_clf = f1_score(y_test, clf_ypred, average = 'weighted')\n",
    "    accuracy_clf = accuracy_score(y_test, clf_ypred)\n",
    "    print (\"F1-score of\", clf_name, \"with TFIDF (use_idf = True) is:\", f1_clf*100)\n",
    "    print (\"Accuracy of\", clf_name, \"with TFIDF (use_idf = True) is:\", accuracy_clf*100)\n",
    "    \n",
    "    if clf_name == \"Support Vector Machine\":\n",
    "        print (clf.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
