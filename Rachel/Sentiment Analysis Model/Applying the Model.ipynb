{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12808\n"
     ]
    }
   ],
   "source": [
    "# data_file = \"SHOPEE_MAYBELLINE_CLEAN_V2.csv\"\n",
    "# data_file = \"Lazada_sentiment.csv\"\n",
    "data_file = \"Shopee_AllData_Sentiment_v2.csv\"\n",
    "data = pd.read_csv(data_file)\n",
    "data.columns = data.columns.str.strip().str.replace(\" \",\"_\")\n",
    "# data.info()\n",
    "# data.head()\n",
    "\n",
    "# data.drop(columns=['Brand','Category','Product_Name','Price','Reviewer','Product_Purchase','Ratings','Date_Of_Review','Response', 'Topic'])\n",
    "# review_list = data['Review'].tolist()\n",
    "# polarity_list = data['Polarity'].tolist()\n",
    "\n",
    "reviews = data['Review']\n",
    "# polarity = data['Polarity']\n",
    "# print (reviews)\n",
    "\n",
    "review_docs = []\n",
    "for each_reviews in reviews:\n",
    "    temp = each_reviews.split(\" \")\n",
    "    review_docs.append(temp)\n",
    "# print (review_docs)\n",
    "\n",
    "# Make sure all words are in lowercase\n",
    "reviews_lower = [[each_word.lower() for each_word in each_review] for each_review in review_docs]\n",
    "# print (reviews_lower)\n",
    "\n",
    "# Use regular expressions to keep only allphabetical words\n",
    "reviews_alpha = [[each_word for each_word in each_review if re.search('^[a-z]+$', each_word)] for each_review in reviews_lower]\n",
    "# print (reviews_alpha)\n",
    "\n",
    "# Remove stop words\n",
    "stop_list = stopwords.words('english')\n",
    "reviews_stop = [[each_word for each_word in each_review if each_word not in stop_list] for each_review in reviews_alpha]\n",
    "# print (reviews_stop)\n",
    "\n",
    "# Porter Stemming\n",
    "stemmer = PorterStemmer()\n",
    "reviews_stem = [[stemmer.stem(each_word) for each_word in each_review] for each_review in reviews_stop]\n",
    "# print (reviews_stem)\n",
    "\n",
    "all_data_cleaned = []\n",
    "for each_sentence in reviews_stem:\n",
    "    sentence = \"\"\n",
    "    for each_word in each_sentence:\n",
    "        sentence += each_word + \" \"\n",
    "    sentence = sentence[0:-1]\n",
    "    all_data_cleaned.append(sentence)\n",
    "# print (all_data_cleaned)\n",
    "\n",
    "polarity_raw = data['Polarity']\n",
    "polarity_0_and_1 = []\n",
    "for each_polarity in polarity_raw:\n",
    "    if int(each_polarity) == int(\"0\"):\n",
    "        polarity_0_and_1.append(0.5)\n",
    "    if int(each_polarity) == int(\"-1\"):\n",
    "        polarity_0_and_1.append(int(0))\n",
    "    if int(each_polarity) == int(\"1\"):\n",
    "        polarity_0_and_1.append(int(1))\n",
    "# print (polarity)\n",
    "\n",
    "print (len(all_data_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 20:59:32.677003\n",
      "1. Count Vectorizer\n",
      "F1-score of SVM:  77.32012381935355\n",
      "Accuracy of SVM:  77.82635852592131\n",
      "{'C': 1, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "2020-03-17 21:08:17.625769\n"
     ]
    }
   ],
   "source": [
    "print (datetime.now())\n",
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "# print (X_test)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "# print (X_test)\n",
    "\n",
    "parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "\n",
    "svmClf = GridSearchCV(estimator = SVC(), param_grid = parameters)\n",
    "svmClf.fit(X_train, y_train)\n",
    "svmClf_ypred = svmClf.predict(X_test)\n",
    "f1_svmClf = f1_score(y_test, svmClf_ypred, average = 'weighted')\n",
    "accuracy_svmClf = accuracy_score(y_test, svmClf_ypred)\n",
    "print (\"F1-score of SVM: \", f1_svmClf*100)\n",
    "print (\"Accuracy of SVM: \", accuracy_svmClf*100)\n",
    "print (svmClf.best_params_)\n",
    "\n",
    "print (datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 510)\t1\n",
      "  (0, 604)\t1\n",
      "  (1, 51)\t1\n",
      "  (2, 531)\t1\n",
      "[ 1 -1  0]\n"
     ]
    }
   ],
   "source": [
    "# tester = [\"nice product\", \"bad\",\"okay\"]\n",
    "# testerX = countVectorizer.transform(tester)\n",
    "\n",
    "# print (testerX)\n",
    "# x_pred = svmClf.predict(testerX)\n",
    "# print (x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 21:22:29.681469\n",
      "2020-03-17 21:22:44.989682\n"
     ]
    }
   ],
   "source": [
    "print (datetime.now())\n",
    "platform_list = data['Platform'].tolist()\n",
    "brand_list = data['Brand'].tolist()\n",
    "category_list = data['Category'].tolist()\n",
    "product_name_list = data['Product_Name'].tolist()\n",
    "price_list = data['Price'].tolist()\n",
    "reviewer_list = data['Reviewer'].tolist()\n",
    "review_list = data['Review'].tolist()\n",
    "review_splitted_list = data['Review_splitted'].tolist()\n",
    "product_purchase_list = data['Product_Purchase'].tolist()\n",
    "rating_list = data['Ratings'].tolist()\n",
    "date_review_list = data['Date_Of_Review'].tolist()\n",
    "response_list = data['Response'].tolist()\n",
    "topic_list = data['topic'].tolist()\n",
    "polarity_list = data['Polarity'].tolist()\n",
    "predicted_polarity_list = []\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "count = 0\n",
    "\n",
    "for i in range(len(review_splitted_list)):\n",
    "    curr_review = [review_splitted_list[i]]\n",
    "    curr_review = tfidfVectorizer.transform(curr_review)\n",
    "    predicted_polarity = svmClf.predict(curr_review)\n",
    "    predicted_polarity_list.append(predicted_polarity[0])\n",
    "    \n",
    "    if int(predicted_polarity) == polarity_list[i]:\n",
    "        count +=1\n",
    "    \n",
    "# print (count)\n",
    "\n",
    "data_file = \"Shopee_AllData_Sentiment_v2.csv\"\n",
    "data = pd.read_csv(data_file)\n",
    "data['Predicted_Polarity'] = predicted_polarity_list\n",
    "data.to_csv('Shopee_AllData_Sentiment_labelled.csv')\n",
    "\n",
    "\n",
    "\n",
    "# new_data = {'Brand':brand_csv, 'Category': category_csv, 'Product Name': product_name_csv, 'Price':prices_csv ,'Reviewer':reviewer_csv,'Review':review_csv, 'Product Purchase':product_variation_csv,'Ratings':rating_csv,'Date Of Review':date_review_csv,'Response':response_csv,'Topic':topic_csv, 'Polarity':polarity_csv }\n",
    "# new_df = pd.DataFrame.from_dict(new_data)\n",
    "# new_df.to_csv('SHOPEE_MAYBELLINE_CLEAN_V2.csv')\n",
    "# print (len(review_list))\n",
    "print (datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
