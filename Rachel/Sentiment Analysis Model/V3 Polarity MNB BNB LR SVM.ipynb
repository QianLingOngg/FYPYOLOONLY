{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data File and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = \"SHOPEE_MAYBELLINE_CLEAN_V2.csv\"\n",
    "data_file = \"Lazada_sentiment.csv\"\n",
    "data = pd.read_csv(data_file)\n",
    "data.columns = data.columns.str.strip().str.replace(\" \",\"_\")\n",
    "# data.info()\n",
    "# data.head()\n",
    "\n",
    "# data.drop(columns=['Brand','Category','Product_Name','Price','Reviewer','Product_Purchase','Ratings','Date_Of_Review','Response', 'Topic'])\n",
    "# review_list = data['Review'].tolist()\n",
    "# polarity_list = data['Polarity'].tolist()\n",
    "\n",
    "reviews = data['Review']\n",
    "# polarity = data['Polarity']\n",
    "# print (reviews)\n",
    "\n",
    "review_docs = []\n",
    "for each_reviews in reviews:\n",
    "    temp = each_reviews.split(\" \")\n",
    "    review_docs.append(temp)\n",
    "# print (review_docs)\n",
    "\n",
    "# Make sure all words are in lowercase\n",
    "reviews_lower = [[each_word.lower() for each_word in each_review] for each_review in review_docs]\n",
    "# print (reviews_lower)\n",
    "\n",
    "# Use regular expressions to keep only allphabetical words\n",
    "reviews_alpha = [[each_word for each_word in each_review if re.search('^[a-z]+$', each_word)] for each_review in reviews_lower]\n",
    "# print (reviews_alpha)\n",
    "\n",
    "# Remove stop words\n",
    "stop_list = stopwords.words('english')\n",
    "reviews_stop = [[each_word for each_word in each_review if each_word not in stop_list] for each_review in reviews_alpha]\n",
    "# print (reviews_stop)\n",
    "\n",
    "# Porter Stemming\n",
    "stemmer = PorterStemmer()\n",
    "reviews_stem = [[stemmer.stem(each_word) for each_word in each_review] for each_review in reviews_stop]\n",
    "# print (reviews_stem)\n",
    "\n",
    "all_data_cleaned = []\n",
    "for each_sentence in reviews_stem:\n",
    "    sentence = \"\"\n",
    "    for each_word in each_sentence:\n",
    "        sentence += each_word + \" \"\n",
    "    sentence = sentence[0:-1]\n",
    "    all_data_cleaned.append(sentence)\n",
    "# print (all_data_cleaned)\n",
    "\n",
    "polarity_raw = data['Polarity']\n",
    "polarity_0_and_1 = []\n",
    "for each_polarity in polarity_raw:\n",
    "    if int(each_polarity) == int(\"0\"):\n",
    "        polarity_0_and_1.append(0.5)\n",
    "    if int(each_polarity) == int(\"-1\"):\n",
    "        polarity_0_and_1.append(int(0))\n",
    "    if int(each_polarity) == int(\"1\"):\n",
    "        polarity_0_and_1.append(int(1))\n",
    "# print (polarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - Multinomial Naive Bayes \n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "F1-score of Multinomial Naive Bayes:  70.62505296771751\n",
      "Accuracy of Multinomial Naive Bayes:  72.85245901639344\n",
      "\n",
      "2. TFIDF Vectorizer\n",
      "F1-score of Multinomial Naive Bayes with TFIDF:  73.45205689395802\n",
      "Accuracy of Multinomial Naive Bayes with TFIDF:  74.88524590163934\n"
     ]
    }
   ],
   "source": [
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "mnbClf = MultinomialNB()\n",
    "mnbClf.fit(X_train, y_train)\n",
    "mnbClf_ypred = mnbClf.predict(X_test)\n",
    "f1_mnbClf = f1_score(y_test, mnbClf_ypred, average = 'weighted')\n",
    "accuracy_mnbClf = accuracy_score(y_test, mnbClf_ypred)\n",
    "print (\"F1-score of Multinomial Naive Bayes: \", f1_mnbClf*100)\n",
    "print (\"Accuracy of Multinomial Naive Bayes: \", accuracy_mnbClf*100)\n",
    "\n",
    "print (\"\\n2. TFIDF Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "mnbTfidfClf = MultinomialNB()\n",
    "mnbTfidfClf.fit(X_train, y_train)\n",
    "mnbTfidfClf_ypred = mnbTfidfClf.predict(X_test)\n",
    "f1_mnbTfidfClf = f1_score(y_test, mnbTfidfClf_ypred, average='weighted')\n",
    "accuracy_mnbTfidfClf = accuracy_score(y_test, mnbTfidfClf_ypred)\n",
    "print (\"F1-score of Multinomial Naive Bayes with TFIDF: \", f1_mnbTfidfClf*100)\n",
    "print (\"Accuracy of Multinomial Naive Bayes with TFIDF: \", accuracy_mnbTfidfClf*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - Bernoulli Naive Bayes\n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "F1-score of Bernoulli Naive Bayes:  78.1315113690941\n",
      "Accuracy of Bernoulli Naive Bayes:  78.68852459016394\n",
      "\n",
      "2. TFIDF Vectorizer\n",
      "F1-score of Bernoulli Naive Bayes with TFIDF:  78.1315113690941\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF:  78.68852459016394\n"
     ]
    }
   ],
   "source": [
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "bnbClf = BernoulliNB()\n",
    "bnbClf.fit(X_train, y_train)\n",
    "bnbClf_ypred = bnbClf.predict(X_test)\n",
    "f1_bnbClf = f1_score(y_test, bnbClf_ypred, average = 'weighted')\n",
    "accuracy_bnbClf = accuracy_score(y_test, bnbClf_ypred)\n",
    "print (\"F1-score of Bernoulli Naive Bayes: \", f1_bnbClf*100)\n",
    "print (\"Accuracy of Bernoulli Naive Bayes: \", accuracy_bnbClf*100)\n",
    "\n",
    "\n",
    "print (\"\\n2. TFIDF Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "bnbTfidfClf = BernoulliNB()\n",
    "bnbTfidfClf.fit(X_train, y_train)\n",
    "bnbTfidfClf_ypred = bnbTfidfClf.predict(X_test)\n",
    "f1_bnbTfidfClf = f1_score(y_test, bnbTfidfClf_ypred, average='weighted')\n",
    "accuracy_bnbTfidfClf = accuracy_score(y_test, bnbTfidfClf_ypred)\n",
    "print (\"F1-score of Bernoulli Naive Bayes with TFIDF: \", f1_bnbTfidfClf*100)\n",
    "print (\"Accuracy of Bernoulli Naive Bayes with TFIDF: \", accuracy_bnbTfidfClf*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model - Logistic Regression\n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "F1-score of Logistic Regression:  79.84358844245423\n",
      "Accuracy of Logistic Regression:  81.04918032786885\n",
      "\n",
      "2. TFIDF Vectorizer\n",
      "F1-score of Logistic Regression with TFIDF:  81.81270330259666\n",
      "Accuracy of Logistic Regression with TFIDF:  82.68852459016394\n"
     ]
    }
   ],
   "source": [
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "logRegClf = LogisticRegression()\n",
    "logRegClf.fit(X_train, y_train)\n",
    "logRegClf_ypred = logRegClf.predict(X_test)\n",
    "f1_logRegClf = f1_score(y_test, logRegClf_ypred, average = 'weighted')\n",
    "accuracy_logRegClf = accuracy_score(y_test, logRegClf_ypred)\n",
    "print (\"F1-score of Logistic Regression: \", f1_logRegClf*100)\n",
    "print (\"Accuracy of Logistic Regression: \", accuracy_logRegClf*100)\n",
    "\n",
    "\n",
    "print (\"\\n2. TFIDF Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "logRegTfidfClf = LogisticRegression()\n",
    "logRegTfidfClf.fit(X_train, y_train)\n",
    "logRegTfidfClf_ypred = logRegTfidfClf.predict(X_test)\n",
    "f1_logRegTfidfClf = f1_score(y_test, logRegTfidfClf_ypred, average='weighted')\n",
    "accuracy_logRegTfidfClf = accuracy_score(y_test, logRegTfidfClf_ypred)\n",
    "print (\"F1-score of Logistic Regression with TFIDF: \", f1_logRegTfidfClf*100)\n",
    "print (\"Accuracy of Logistic Regression with TFIDF: \", accuracy_logRegTfidfClf*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model - Support Vector Machine\n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer\n",
    "3. Count Vectorizer with Tuning\n",
    "4. TFIDF Vectorizer with Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "F1-score of SVM:  32.86082463112957\n",
      "Accuracy of SVM:  49.57377049180327\n",
      "\n",
      "2. TFIDF Vectorizer\n",
      "F1-score of SVM with TFIDF:  81.81270330259666\n",
      "Accuracy of SVM with TFIDF:  82.68852459016394\n",
      "\n",
      "3. Count Vectorizer with Tuning\n",
      "F1-score of SVM with Tuning:  86.38192827841739\n",
      "Accuracy of SVM with Tuning:  86.49180327868852\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "4. TFIDF Vectorizer with Tuning\n",
      "F1-score of SVM with TFIDF with Tuning:  86.52612669729935\n",
      "Accuracy of SVM with TFIDF with Tuning:  86.62295081967213\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "svmClf = SVC()\n",
    "svmClf.fit(X_train, y_train)\n",
    "svmClf_ypred = svmClf.predict(X_test)\n",
    "f1_svmClf = f1_score(y_test, svmClf_ypred, average = 'weighted')\n",
    "accuracy_svmClf = accuracy_score(y_test, svmClf_ypred)\n",
    "print (\"F1-score of SVM: \", f1_svmClf*100)\n",
    "print (\"Accuracy of SVM: \", accuracy_svmClf*100)\n",
    "\n",
    "\n",
    "print (\"\\n2. TFIDF Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "svmTfidfClf = LogisticRegression()\n",
    "svmTfidfClf.fit(X_train, y_train)\n",
    "svmTfidfClf_ypred = svmTfidfClf.predict(X_test)\n",
    "f1_svmTfidfClf = f1_score(y_test, svmTfidfClf_ypred, average='weighted')\n",
    "accuracy_svmTfidfClf = accuracy_score(y_test, svmTfidfClf_ypred)\n",
    "print (\"F1-score of SVM with TFIDF: \", f1_svmTfidfClf*100)\n",
    "print (\"Accuracy of SVM with TFIDF: \", accuracy_svmTfidfClf*100)\n",
    "\n",
    "print (\"\\n3. Count Vectorizer with Tuning\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "# parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "\n",
    "svmClfTuned = GridSearchCV(estimator=SVC(), param_grid=parameters)\n",
    "svmClfTuned.fit(X_train, y_train)\n",
    "svmClfTuned_ypred = svmClfTuned.predict(X_test)\n",
    "f1_svmClfTuned = f1_score(y_test, svmClfTuned_ypred, average = 'weighted')\n",
    "accuracy_svmClfTuned = accuracy_score(y_test, svmClfTuned_ypred)\n",
    "print (\"F1-score of SVM with Tuning: \", f1_svmClfTuned*100)\n",
    "print (\"Accuracy of SVM with Tuning: \", accuracy_svmClfTuned*100)\n",
    "print(svmClfTuned.best_params_)\n",
    "\n",
    "\n",
    "print (\"\\n4. TFIDF Vectorizer with Tuning\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = data['Polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "# parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "\n",
    "svmTfidfClfTuned = GridSearchCV(estimator=SVC(), param_grid=parameters)\n",
    "svmTfidfClfTuned.fit(X_train, y_train)\n",
    "svmTfidfClfTuned_ypred = svmTfidfClfTuned.predict(X_test)\n",
    "f1_svmTfidfClfTuned = f1_score(y_test, svmTfidfClfTuned_ypred, average='weighted')\n",
    "accuracy_svmTfidfClfTuned = accuracy_score(y_test, svmTfidfClfTuned_ypred)\n",
    "print (\"F1-score of SVM with TFIDF with Tuning: \", f1_svmTfidfClfTuned*100)\n",
    "print (\"Accuracy of SVM with TFIDF with Tuning: \", accuracy_svmTfidfClfTuned*100)\n",
    "print (svmTfidfClfTuned.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Multinomial Naive Bayes:  70.62505296771751\n",
      "Accuracy of Multinomial Naive Bayes:  72.85245901639344\n",
      "F1-score of Multinomial Naive Bayes with TFIDF:  73.45205689395802\n",
      "Accuracy of Multinomial Naive Bayes with TFIDF:  74.88524590163934\n",
      "\n",
      "\n",
      "F1-score of Bernoulli Naive Bayes:  78.1315113690941\n",
      "Accuracy of Bernoulli Naive Bayes:  78.68852459016394\n",
      "F1-score of Bernoulli Naive Bayes with TFIDF:  78.1315113690941\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF:  78.68852459016394\n",
      "\n",
      "\n",
      "F1-score of Logistic Regression:  79.84358844245423\n",
      "Accuracy of Logistic Regression:  81.04918032786885\n",
      "F1-score of Logistic Regression with TFIDF:  81.81270330259666\n",
      "Accuracy of Logistic Regression with TFIDF:  82.68852459016394\n",
      "\n",
      "\n",
      "F1-score of SVM:  32.86082463112957\n",
      "Accuracy of SVM:  49.57377049180327\n",
      "F1-score of SVM with TFIDF:  81.81270330259666\n",
      "Accuracy of SVM with TFIDF:  82.68852459016394\n",
      "\n",
      "\n",
      "F1-score of SVM with Tuning:  86.38192827841739\n",
      "Accuracy of SVM with Tuning:  86.49180327868852\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "F1-score of SVM with TFIDF with Tuning:  86.52612669729935\n",
      "Accuracy of SVM with TFIDF with Tuning:  86.62295081967213\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print (\"F1-score of Multinomial Naive Bayes: \", f1_mnbClf*100)\n",
    "print (\"Accuracy of Multinomial Naive Bayes: \", accuracy_mnbClf*100)\n",
    "print (\"F1-score of Multinomial Naive Bayes with TFIDF: \", f1_mnbTfidfClf*100)\n",
    "print (\"Accuracy of Multinomial Naive Bayes with TFIDF: \", accuracy_mnbTfidfClf*100)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of Bernoulli Naive Bayes: \", f1_bnbClf*100)\n",
    "print (\"Accuracy of Bernoulli Naive Bayes: \", accuracy_bnbClf*100)\n",
    "print (\"F1-score of Bernoulli Naive Bayes with TFIDF: \", f1_bnbTfidfClf*100)\n",
    "print (\"Accuracy of Bernoulli Naive Bayes with TFIDF: \", accuracy_bnbTfidfClf*100)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of Logistic Regression: \", f1_logRegClf*100)\n",
    "print (\"Accuracy of Logistic Regression: \", accuracy_logRegClf*100)\n",
    "print (\"F1-score of Logistic Regression with TFIDF: \", f1_logRegTfidfClf*100)\n",
    "print (\"Accuracy of Logistic Regression with TFIDF: \", accuracy_logRegTfidfClf*100)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of SVM: \", f1_svmClf*100)\n",
    "print (\"Accuracy of SVM: \", accuracy_svmClf*100)\n",
    "print (\"F1-score of SVM with TFIDF: \", f1_svmTfidfClf*100)\n",
    "print (\"Accuracy of SVM with TFIDF: \", accuracy_svmTfidfClf*100)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of SVM with Tuning: \", f1_svmClfTuned*100)\n",
    "print (\"Accuracy of SVM with Tuning: \", accuracy_svmClfTuned*100)\n",
    "print(svmClfTuned.best_params_)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of SVM with TFIDF with Tuning: \", f1_svmTfidfClfTuned*100)\n",
    "print (\"Accuracy of SVM with TFIDF with Tuning: \", accuracy_svmTfidfClfTuned*100)\n",
    "print (svmTfidfClfTuned.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR :(\n",
    "### Build a Model - ANN\n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Train on 349 samples, validate on 117 samples\n",
      "Epoch 1/10\n",
      "349/349 [==============================] - 0s 953us/sample - loss: 1.2774 - accuracy: 0.6275 - val_loss: 1.1562 - val_accuracy: 0.7521\n",
      "Epoch 2/10\n",
      "349/349 [==============================] - 0s 358us/sample - loss: 1.0059 - accuracy: 0.7679 - val_loss: 0.8903 - val_accuracy: 0.7521\n",
      "Epoch 3/10\n",
      "349/349 [==============================] - 0s 337us/sample - loss: 0.7590 - accuracy: 0.7679 - val_loss: 0.7085 - val_accuracy: 0.7521\n",
      "Epoch 4/10\n",
      "349/349 [==============================] - 0s 320us/sample - loss: 0.6216 - accuracy: 0.7679 - val_loss: 0.6248 - val_accuracy: 0.7521\n",
      "Epoch 5/10\n",
      "349/349 [==============================] - 0s 320us/sample - loss: 0.5542 - accuracy: 0.7679 - val_loss: 0.5805 - val_accuracy: 0.7521\n",
      "Epoch 6/10\n",
      "349/349 [==============================] - 0s 324us/sample - loss: 0.5134 - accuracy: 0.7679 - val_loss: 0.5504 - val_accuracy: 0.7521\n",
      "Epoch 7/10\n",
      "349/349 [==============================] - 0s 295us/sample - loss: 0.4783 - accuracy: 0.7679 - val_loss: 0.5282 - val_accuracy: 0.7521\n",
      "Epoch 8/10\n",
      "349/349 [==============================] - 0s 298us/sample - loss: 0.4460 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7692\n",
      "Epoch 9/10\n",
      "349/349 [==============================] - 0s 304us/sample - loss: 0.4154 - accuracy: 0.7822 - val_loss: 0.4880 - val_accuracy: 0.7778\n",
      "Epoch 10/10\n",
      "349/349 [==============================] - 0s 313us/sample - loss: 0.3835 - accuracy: 0.7937 - val_loss: 0.4761 - val_accuracy: 0.7778\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "def createModel():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(16, input_dim = X_train.shape[1], kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(layers.Dense(8, activation='tanh'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "    return (model)\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "polarity = polarity_0_and_1\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "model = createModel()\n",
    "annClf = model.fit(X_train, y_train, epochs=num_epochs, \n",
    "                   validation_data=(X_test, y_test), \n",
    "                   batch_size = batch_size)\n",
    "\n",
    "annClf_ypred = model.predict(X_test)\n",
    "annClf_ypred = np.argmax(annClf_ypred)\n",
    "annClf_ytest = np.argmax(y_test)\n",
    "# f1_annClf = f1_score(y_test, annClf_ypred, average='weighted')\n",
    "# accuracy_annClf = f1_score(annClf_ytest, annClf_ypred)\n",
    "# print (\"F1-score of ANN: \", f1_annClf*100)\n",
    "# print (\"Accuracy of ANN: \", accuracy_annClf*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with LSTM\n",
    "1. https://medium.com/@mrunal68/text-sentiments-classification-with-cnn-and-lstm-f92652bc29fd\n",
    "2. https://medium.com/datadriveninvestor/deep-learning-techniques-for-text-classification-9392ca9492c7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews = all_data_cleaned\n",
    "# polarity = data['Polarity']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(reviews, polarity, test_size=0.25, random_state=42)\n",
    "\n",
    "# tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "# X_train = tfidfVectorizer.fit_transform(X_train).toarray()\n",
    "# X_test = tfidfVectorizer.transform(X_test).toarray()\n",
    "\n",
    "# # DNN\n",
    "# def buildDNNModel(shape, nClasses, dropout=0.5)\n",
    "#     model = tf.keras.Sequential()\n",
    "#     node = 512\n",
    "#     nLayers = 4\n",
    "    \n",
    "#     model.add(Dense(node, input_dim=shapte, activation='relu'))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     for i in range(0, nLayers):\n",
    "#         model.add(Dense(node, input_dim=node, activation='relu'))\n",
    "#         model.add(Dropout(dropout))\n",
    "#     model.add(Dense(nClasses,activation='softmax'))\n",
    "    \n",
    "#     model.compile(loss='sparse_categorical_crossentropy',\n",
    "#                  optimizer=tf.optimizers.Adam(),\n",
    "#                  metrics=['accuracy'])\n",
    "#     return (model)\n",
    "\n",
    "# model_DNN = buildDNNModel(X_train.shape[1],3)\n",
    "# model_DNN.fit(X_train, y_train,\n",
    "#              validation_data = (X_test, y_test),\n",
    "#              epochs=10,\n",
    "#              batch_size=128,\n",
    "#              verbose=2)\n",
    "# predicted = model_DNN.predict(X_test)\n",
    "# print (metrics.classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
