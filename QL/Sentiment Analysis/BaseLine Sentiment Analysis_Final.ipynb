{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8987 entries, 0 to 8986\n",
      "Data columns (total 14 columns):\n",
      "Unnamed:_0          8987 non-null int64\n",
      "Unnamed:_0.1        8987 non-null int64\n",
      "Platform            8987 non-null object\n",
      "Brand               8987 non-null object\n",
      "Category            8987 non-null object\n",
      "Product_Name        8987 non-null object\n",
      "Price               8987 non-null float64\n",
      "Reviewer            8965 non-null object\n",
      "Review              8987 non-null object\n",
      "Product_Purchase    7382 non-null object\n",
      "Ratings             8965 non-null float64\n",
      "Date_Of_Review      8965 non-null object\n",
      "Response            8965 non-null object\n",
      "topic               8987 non-null object\n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 983.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed:_0</th>\n",
       "      <th>Unnamed:_0.1</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Category</th>\n",
       "      <th>Product_Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Review</th>\n",
       "      <th>Product_Purchase</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Date_Of_Review</th>\n",
       "      <th>Response</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>zenheng</td>\n",
       "      <td>delivery was quite fast, and item was on disco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2/6/2020 23:58</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>glennoeestaquio</td>\n",
       "      <td>received item sealed properly.\\r\\r\\r\\r\\nquick ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2/6/2020 12:44</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>shy2206</td>\n",
       "      <td>yet to try but delivery was prompt and product...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2/6/2020 10:21</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>lindamiyalin</td>\n",
       "      <td>well wrapped,  in good condition,  super fast ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1/30/2020 23:01</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>kyc385</td>\n",
       "      <td>well packed, will buy again</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2/1/2020 11:40</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed:_0  Unnamed:_0.1 Platform          Brand           Category  \\\n",
       "0           0             0   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "1           1             1   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "2           2             2   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "3           3             3   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "4           4             4   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "\n",
       "                                        Product_Name  Price         Reviewer  \\\n",
       "0  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9          zenheng   \n",
       "1  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9  glennoeestaquio   \n",
       "2  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9          shy2206   \n",
       "3  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9     lindamiyalin   \n",
       "4  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9           kyc385   \n",
       "\n",
       "                                              Review Product_Purchase  \\\n",
       "0  delivery was quite fast, and item was on disco...              NaN   \n",
       "1  received item sealed properly.\\r\\r\\r\\r\\nquick ...              NaN   \n",
       "2  yet to try but delivery was prompt and product...              NaN   \n",
       "3  well wrapped,  in good condition,  super fast ...              NaN   \n",
       "4                        well packed, will buy again              NaN   \n",
       "\n",
       "   Ratings   Date_Of_Review Response     topic  \n",
       "0      4.0   2/6/2020 23:58       no  delivery  \n",
       "1      5.0   2/6/2020 12:44       no  delivery  \n",
       "2      5.0   2/6/2020 10:21       no  delivery  \n",
       "3      5.0  1/30/2020 23:01       no  delivery  \n",
       "4      5.0   2/1/2020 11:40       no  delivery  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datafile\n",
    "data_file = \"data_with_topic_v2.csv\"\n",
    "data = pd.read_csv(data_file)\n",
    "data.columns = data.columns.str.strip().str.replace(\" \",\"_\") # reason for doing this is cause cannot get columns with space into a list\n",
    "\n",
    "#reformat the respective columns\n",
    "\n",
    "#lower case\n",
    "data['Review'] = [word.lower() for word in data['Review']]\n",
    "\n",
    "#Strip off the Variation Word\n",
    "data['Product_Purchase'] = data['Product_Purchase'].str.strip(\"Variation:\")\n",
    "\n",
    "#Change Date of Review to DateTime\n",
    "#data['Date_Of_Review'] = pd.to_datetime(data['Date_Of_Review'])\n",
    "\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation and Initalise of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataset is: 8987\n"
     ]
    }
   ],
   "source": [
    "# make the old csv data into a list\n",
    "\n",
    "row_id_list = data['Unnamed:_0'].tolist()\n",
    "platform_list = data['Platform'].tolist()\n",
    "brand_list = data['Brand'].tolist()\n",
    "category_list = data['Category'].tolist()\n",
    "product_name_list = data['Product_Name'].tolist()\n",
    "price_list = data['Price'].tolist()\n",
    "reviewer_list = data['Reviewer'].tolist()\n",
    "review_list = data['Review'].tolist()\n",
    "product_variation_list = data['Product_Purchase'].tolist()\n",
    "rating_list = data['Ratings'].tolist()\n",
    "date_review_list = data[\"Date_Of_Review\"].tolist()\n",
    "response_list = data[\"Response\"].tolist()\n",
    "topic_list = data[\"topic\"].tolist()\n",
    "\n",
    "# initialising the new columns\n",
    "\n",
    "id_csv=[]\n",
    "platform_csv=[]\n",
    "brand_csv = []\n",
    "category_csv = []\n",
    "product_name_csv = []\n",
    "prices_csv = []\n",
    "reviewer_csv =[]\n",
    "review_splitted_csv = []\n",
    "review_csv=[]\n",
    "product_variation_csv = []\n",
    "rating_csv = []\n",
    "date_review_csv = []\n",
    "response_csv = []\n",
    "topic_csv=[]\n",
    "\n",
    "# this is the length of the csv old data\n",
    "print (\"The length of the dataset is:\", len(brand_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"aren't\": 'are not', \"can't\": 'cannot', \"couldn't\": 'could not', \"didn't\": 'did not', \"doesn't\": 'does not', \"don't\": 'do not', \"hadn't\": 'had not', \"hasn't\": 'has not', \"haven't\": 'have not', \"he'd\": 'he would', \"he'll\": 'he will', \"he's\": 'he is', \"i'd\": 'I had', \"i'll\": 'I will', \"i'm\": 'I am', \"isn't\": 'is not', \"it's\": 'it is', \"it'll\": 'it will', \"i've\": 'I have', \"let's\": 'let us', \"l'oreal\": 'loreal', \"mightn't\": 'might not', \"mustn't\": 'must not', \"shan't\": 'shall not', \"she'd\": 'she would', \"she'll\": 'she will', \"she's\": 'she is', \"shouldn't\": 'should not', \"that's\": 'that is', \"there's\": 'there is', \"they'd\": 'they would', \"they'll\": 'they will', \"they're\": 'they are', \"they've\": 'they have', \"we'd\": 'we would', \"we're\": 'we are', \"weren't\": 'were not', \"we've\": 'we have', \"what'll\": 'what will', \"what're\": 'what are', \"what's\": 'what is', \"what've\": 'what have', \"where's\": 'where is', \"who'd\": 'who would', \"who'll\": 'who will', \"who're\": 'who are', \"who's\": 'who is', \"who've\": 'who have', \"won't\": 'will not', \"wouldn't\": 'would not', \"you'd\": 'you would', \"you'll\": 'you will', \"you're\": 'you are', \"you've\": 'you have', \"'re\": ' are', \"wasn't\": 'was not', \"we'll\": ' will'}\n"
     ]
    }
   ],
   "source": [
    "#upload the appos\n",
    "from word_dict import appos\n",
    "\n",
    "print(appos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the Date Format [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date =[]\n",
    "for i in range(len(brand_list)):\n",
    "    \n",
    "    date_review = date_review_list[i]\n",
    "    \n",
    "    if platform_list[i] == 'Lazada':\n",
    "        if 'days ago' in date_review or 'day ago' in date_review :\n",
    "            day = date_review.replace('days ago', '').replace('day ago', '')\n",
    "            date_review = datetime.today() - timedelta(days=int(day))\n",
    "            date_review = date_review.strftime(\"%d-%b-%y\")\n",
    "#             print(\"trans\",date_review)\n",
    "\n",
    "        elif 'weeks ago' in date_review or 'week ago' in date_review:\n",
    "            day = date_review.replace('weeks ago', '').replace('week ago', '')\n",
    "            day = int(day)*7\n",
    "            date_review = datetime.today() - timedelta(days=day)\n",
    "            date_review = date_review.strftime(\"%d-%b-%y\")\n",
    "#             print(\"trans\",date_review)\n",
    "\n",
    "        elif 'hours ago' in date_review or 'hour ago' in date_review:\n",
    "            hours = date_review.replace('hours ago', '').replace('hour ago', '')\n",
    "            date_review = datetime.today() - timedelta(hours=int(hours))\n",
    "            date_review = date_review.strftime(\"%d-%b-%y\")\n",
    "    \n",
    "#         print(\"trans\",date_review)\n",
    "        new_date.append(date_review)\n",
    "    else:\n",
    "#         print(platform_list[i])\n",
    "        new_date.append(date_review)\n",
    "        \n",
    "data[\"Date_Of_Review\"] = new_date\n",
    "\n",
    "new_date_review_list = data[\"Date_Of_Review\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spilt the Sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "for i in range(len(brand_list)):\n",
    "    # current_review is a string\n",
    "    current_review = review_list[i]\n",
    "    \n",
    "    #spilt the sentence\n",
    "    splitted_sentence= re.split(r'[.!]', current_review) \n",
    "    #print(splitted_sentence)\n",
    "    \n",
    "    for j in range(len(splitted_sentence)):\n",
    "        \n",
    "        splitted_sentence[j].strip()\n",
    "        if len(splitted_sentence[j]) > 0 :\n",
    "            \n",
    "            processed_review = splitted_sentence[j].strip()\n",
    "            \n",
    "            # Negation handling\n",
    "            processed_review = processed_review.split()\n",
    "            processed_review =[appos[w] if w in appos else w for w in processed_review]\n",
    "            processed_review = \" \".join(processed_review) \n",
    "            \n",
    "            processed_review = processed_review.strip()\n",
    "            # Remove all the special characters\n",
    "            processed_review = re.sub(r'\\W', ' ', processed_review)\n",
    "            # Removing prefixed 'b'\n",
    "            processed_review = re.sub(r'^b\\s+', '', processed_review)\n",
    "            # remove all single characters contains a white space character\n",
    "            processed_review= re.sub(r'^[a-zA-Z]$', ' ', processed_review)\n",
    "            # Substituting multiple spaces with single space\n",
    "            processed_review = re.sub(r'\\s+', ' ', processed_review, flags=re.I)\n",
    "          \n",
    "            \n",
    "            processed = processed_review.strip()\n",
    "            #print(processed)\n",
    "            \n",
    "            # final check if the processed_review is empty\n",
    "            final = []\n",
    "            if processed != \"\":\n",
    "                tokenized = word_tokenize(processed)\n",
    "                #removed additional letters eg \"gooooooodddddd\" to \"good\"\n",
    "                for w in tokenized:\n",
    "                    processed_2 = reduce_lengthening(w)\n",
    "                    processed_2 = spell.correction(processed_2)\n",
    "                    final.append(processed_2)\n",
    "                final =' '.join(final)\n",
    "                #print(final)\n",
    "                # append into a dictionary\n",
    "                platform_csv.append(platform_list[i])\n",
    "                id_csv.append(row_id_list[i])\n",
    "                brand_csv.append(brand_list[i])\n",
    "                category_csv.append(category_list[i])\n",
    "                product_name_csv.append(product_name_list[i])\n",
    "                prices_csv.append(price_list[i])\n",
    "                reviewer_csv.append(reviewer_list[i])\n",
    "                review_csv.append(current_review)\n",
    "                review_splitted_csv.append(final)\n",
    "                product_variation_csv.append(product_variation_list[i])\n",
    "                rating_csv.append(rating_list[i])\n",
    "                date_review_csv.append(new_date_review_list[i])\n",
    "                response_csv.append(response_list[i])\n",
    "                topic_csv.append(topic_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17119 entries, 0 to 17118\n",
      "Data columns (total 14 columns):\n",
      "ID                  17119 non-null int64\n",
      "Platform            17119 non-null object\n",
      "Brand               17119 non-null object\n",
      "Category            17119 non-null object\n",
      "Product Name        17119 non-null object\n",
      "Price               17119 non-null float64\n",
      "Reviewer            17097 non-null object\n",
      "Review              17119 non-null object\n",
      "Review_splitted     17119 non-null object\n",
      "Product Purchase    14421 non-null object\n",
      "Ratings             17097 non-null float64\n",
      "Date Of Review      17097 non-null datetime64[ns]\n",
      "Response            17097 non-null object\n",
      "Topic               17119 non-null object\n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(10)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Store into a new data frame\n",
    "splitted_data = {'ID':id_csv,'Platform':platform_csv ,'Brand':brand_csv, 'Category': category_csv, 'Product Name ': product_name_csv, 'Price':prices_csv ,'Reviewer':reviewer_csv,'Review':review_csv, 'Review_splitted':review_splitted_csv, 'Product Purchase':product_variation_csv,'Ratings':rating_csv,'Date Of Review':date_review_csv,'Response': response_csv , 'Topic':topic_csv}\n",
    "splitted_df = pd.DataFrame.from_dict(splitted_data)\n",
    "splitted_df['Date Of Review'] = pd.to_datetime(splitted_df['Date Of Review'])\n",
    "splitted_df.head()\n",
    "splitted_df.info()\n",
    "\n",
    "splitted_df.to_csv('AllData_Process.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "def lemmatization(texts):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = sp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc ])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_splitted</th>\n",
       "      <th>Product Purchase</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Date Of Review</th>\n",
       "      <th>Response</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>zenheng</td>\n",
       "      <td>delivery was quite fast, and item was on disco...</td>\n",
       "      <td>delivery was quite fast and item was on discou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-02-06 23:58:00</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>zenheng</td>\n",
       "      <td>delivery was quite fast, and item was on disco...</td>\n",
       "      <td>so far liking this product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-02-06 23:58:00</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>zenheng</td>\n",
       "      <td>delivery was quite fast, and item was on disco...</td>\n",
       "      <td>will continue to use it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-02-06 23:58:00</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>glennoeestaquio</td>\n",
       "      <td>received item sealed properly.\\r\\r\\r\\r\\nquick ...</td>\n",
       "      <td>received item sealed properly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-02-06 12:44:00</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>L'Oreal Paris</td>\n",
       "      <td>Serum &amp; Treatment</td>\n",
       "      <td>L'Oreal Paris Revitalift Crystal Micro-Essence...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>glennoeestaquio</td>\n",
       "      <td>received item sealed properly.\\r\\r\\r\\r\\nquick ...</td>\n",
       "      <td>quick delivery too</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-02-06 12:44:00</td>\n",
       "      <td>no</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Platform          Brand           Category  \\\n",
       "0   0   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "1   0   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "2   0   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "3   1   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "4   1   Shopee  L'Oreal Paris  Serum & Treatment   \n",
       "\n",
       "                                       Product Name   Price         Reviewer  \\\n",
       "0  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9          zenheng   \n",
       "1  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9          zenheng   \n",
       "2  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9          zenheng   \n",
       "3  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9  glennoeestaquio   \n",
       "4  L'Oreal Paris Revitalift Crystal Micro-Essence...   25.9  glennoeestaquio   \n",
       "\n",
       "                                              Review  \\\n",
       "0  delivery was quite fast, and item was on disco...   \n",
       "1  delivery was quite fast, and item was on disco...   \n",
       "2  delivery was quite fast, and item was on disco...   \n",
       "3  received item sealed properly.\\r\\r\\r\\r\\nquick ...   \n",
       "4  received item sealed properly.\\r\\r\\r\\r\\nquick ...   \n",
       "\n",
       "                                     Review_splitted Product Purchase  \\\n",
       "0  delivery was quite fast and item was on discou...              NaN   \n",
       "1                         so far liking this product              NaN   \n",
       "2                            will continue to use it              NaN   \n",
       "3                      received item sealed properly              NaN   \n",
       "4                                 quick delivery too              NaN   \n",
       "\n",
       "   Ratings      Date Of Review Response     Topic  \n",
       "0      4.0 2020-02-06 23:58:00       no  delivery  \n",
       "1      4.0 2020-02-06 23:58:00       no  delivery  \n",
       "2      4.0 2020-02-06 23:58:00       no  delivery  \n",
       "3      5.0 2020-02-06 12:44:00       no  delivery  \n",
       "4      5.0 2020-02-06 12:44:00       no  delivery  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "\n",
    "review_cleaned=[]\n",
    "stop_list = stopwords.words('english')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "sp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "splitted_df= splitted_df[splitted_df.Review_splitted != 'no comments review is an image']\n",
    "tokenized_review = splitted_df[\"Review_splitted\"]\n",
    "\n",
    "\n",
    "for sentence in tokenized_review:\n",
    "    tokenized_review = nltk.word_tokenize(sentence)\n",
    "    review_stopremoved = [w for w in tokenized_review if w not in stop_list]\n",
    "#     review_translate = [gs.translate(w,'en') for w in review_stopremoved if re.findall(r'[\\u4e00-\\u9fff]+', w)]\n",
    "#     print(review_translate)\n",
    "    review_cleaned.append(review_stopremoved)\n",
    "\n",
    "# Lemmatized all the words\n",
    "data_lemmatized = lemmatization(review_cleaned)\n",
    "#print(data_lemmatized)\n",
    "\n",
    "\n",
    "#splitted_df['tokenized_review'] = data_lemmatized    \n",
    "splitted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## translator\n",
    "# import goslate\n",
    "\n",
    "# text = \"价格合理\"\n",
    "\n",
    "# gs = goslate.Goslate()\n",
    "# translatedText = gs.translate(text,'en')\n",
    "# print(translatedText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Positive , Negative , Increment , Decrement and Inverse Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "\n",
    "pos_lexicon = 'dict/positive-words.txt'\n",
    "neg_lexicon = 'dict/negative-words.txt'\n",
    "inc_words = 'dict/increment-words.txt'\n",
    "dec_words = 'dict/decrement-words.txt'\n",
    "inv_words = 'dict/inverse-words.txt'\n",
    "\n",
    "\n",
    "# Read the positive sentiment lexicon.\n",
    "pos_dict = {}\n",
    "f = open(pos_lexicon, 'r', encoding = \"ISO-8859-1\")\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    pos_dict[line] = 1\n",
    "f.close()\n",
    "\n",
    "# Read the negative sentiment lexicon.\n",
    "neg_dict = {}\n",
    "f = open(neg_lexicon, 'r', encoding = \"ISO-8859-1\")\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    neg_dict[line] = 1\n",
    "f.close()\n",
    "\n",
    "\n",
    "# Read the increment words.\n",
    "inc_dict = {}\n",
    "f = open(inc_words, 'r', encoding = \"ISO-8859-1\")\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    inc_dict[line] = 1\n",
    "f.close()\n",
    "\n",
    "# Read the decrement words.\n",
    "dec_dict = {}\n",
    "f = open(dec_words, 'r', encoding = \"ISO-8859-1\")\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    dec_dict[line] = 1\n",
    "f.close()\n",
    "\n",
    "# Read the inverse words.\n",
    "inv_dict = {}\n",
    "f = open(inv_words, 'r', encoding = \"ISO-8859-1\")\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    inv_dict[line] = 1\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon-based Sentiment Polarity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "score_label=[]\n",
    "\n",
    "for sent in data_lemmatized:\n",
    "    total_score = 0\n",
    "   # print(sent)\n",
    "    for w in sent:\n",
    "        score = 0\n",
    "        if w in pos_dict:\n",
    "            score = 1\n",
    "        elif w in neg_dict:\n",
    "            score = -1\n",
    "        #check previous word\n",
    "        position = sent.index(w)\n",
    "        previous_word = sent[position-1]\n",
    "        if previous_word is not None:\n",
    "            if previous_word in inc_dict : \n",
    "                score *= 2.0\n",
    "            elif previous_word in dec_dict:\n",
    "                score /=2\n",
    "            elif previous_word in inv_dict:\n",
    "                score *= -1  \n",
    "        total_score+=score\n",
    "    \n",
    "    if total_score >0:\n",
    "        predicted_labels.append('1')\n",
    "        \n",
    "    elif total_score <0:\n",
    "        predicted_labels.append('-1')\n",
    "    else:\n",
    "        predicted_labels.append('0')\n",
    "        \n",
    "    score_label.append(int(total_score))\n",
    "    #print(total_score)\n",
    "\n",
    "splitted_df[\"Polarity\"] = predicted_labels\n",
    "splitted_df[\"Score\"] = score_label\n",
    "# splitted_df.to_csv('AllData_Sentiment.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Polarity for Splitted Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "\n",
    "#find the mode of each review\n",
    "result = splitted_df.groupby('ID')['Polarity'].agg(lambda x:x.value_counts().index[0])\n",
    "#print(result)\n",
    "\n",
    "# insert a overall polarity col, with the mode value\n",
    "splitted_df['Overall Polarity'] = [result[id] for id in splitted_df['ID']]\n",
    "splitted_df.to_csv('AllData_DashBoard.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
